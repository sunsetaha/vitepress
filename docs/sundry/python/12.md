# 抓取多级页面数据
应用场景：一般页面是列表，每一项以`<a>`标签的形式链接到详情页，因此只有到详情页后才能获取到数据。

## 【示例】电影天堂年最新电影爬取

```
https://www.dytt8.net/html/gndy/dyzz/list_23_1.html
https://www.dytt8.net/html/gndy/dyzz/list_23_2.html
...
```
1) 分析地址规律
   2) 通过源码确定正则表达式

      1) 一级页面
      ```html
      ...
         <table width="100%" border="0" cellspacing="0" cellpadding="0" class="tbspan" style="margin-top:6px">
            <tbody><tr> 
            <td height="1" colspan="2" background="/templets/img/dot_hor.gif"></td>
            </tr>
            <tr> 
            <td width="5%" height="26" align="center"><img src="/templets/img/item.gif" width="18" height="17"></td>
            <td height="26">
                <b>
                    <a href="/html/gndy/dyzz/20240429/64938.html" class="ulink">2024年剧情喜剧《飞驰人生2》HD国语中英双字</a>
                </b>
            </td>
            </tr>
            <tr> 
            <td height="20" style="padding-left:3px">&nbsp;</td>
            <td style="padding-left:3px">
                            <font color="#8F8C89">日期：2024-04-29 10:12:08 
             </font>
         
                            </td>
            </tr>
            <tr> 
            <td colspan="2" style="padding-left:3px">◎译 名 Pegasus 2 ◎片 名 飞驰人生2 ◎年 代 2024 ◎产 地 中国大陆 ◎类 别 剧情/喜剧/运动 ◎语 言 普通话 ◎字 幕 中英双字 ◎上映日期 2024-02-10(中国大陆) ◎IMDb评分7.2/10 from 538 users ◎豆瓣评分 7.7/10 from 511435 users ◎片 长 121分钟 ◎导 演 韩寒</td>
            </tr>
            </tbody>
        </table>
      ...
      ```
      通过源码确定其中的a标签，中的href属性是我们需要抓取的数据。
      ```regexp
       <table width="100%".*?<td width="5%".*?<a href="(.*?)".*?ulink">.*?</table>
      ```
      2) 详情页面同上
      点击二级页面进入详情页，通过开发者工具分析想要数据的网页元素，即电影名称，和下载链接，其正则表达式如下
      ```regexp
        <div class="title_all"><h1><font color=#07519a>(.*?)</font></h1></div>.*?<div><a href="(.*?)">.*?</a>
      ```
      
## 爬虫增量抓取
爬虫是一种效率很低的程序，非常消耗计算机资源。对于聚焦爬虫程序而言，需要每天对特定的网站进行数据抓取，如果每次都去抓取之前已经抓取过的数据，就会白白消耗了时间和资源。而增量爬虫是指通过监测网站更新的情况，只抓取最新数据的一种方式，这样就大大降低了资源的消耗。

对于本节案例来说，电影天堂网站每天都会更新内容，因此编写一个增量抓取的爬虫程序是非常合适的。

那么要如何判断爬虫程序是否已抓取过二级页面的 url 呢？其实，当您第一次运行爬虫程序时，爬虫会将所有的 url 抓取下来，然后将这些 url 放入数据库中。为了提高数据库的查询效率，您可以为每一个 url 生成专属的“指纹”。当网站更新后，第二次运行爬虫程序时，程序只会对数据库中不存在的指纹进行抓取。


## 代码实现

### 建库建表

```sql
create database movieskydb charset utf8;
use movieskydb;
create table request_finger(
finger char(60)
)charset=utf8;
create table movieinfo(
moviename varchar(300),
downloadaddr varchar(600)
)charset=utf8;
```


### url指纹生成-使用内置hashlib库 md5 来生成指纹
```python
#导入模块
from hashlib import md5
#待加密的url
url="https://www.dytt8.net/html/gndy/dyzz/20210226/61131.html"
# 生成MD5对象
secret = md5()
# 加密url
secret.update(url.encode())
# 提取十六进制的加密串
finger = secret.hexdigest()
print(finger) 
# 输出结果
# 2d5e46ee52756e8ae59c9ba42230b883
```
### 爬虫程序

```python

