# 爬取网页

需求：抓取网页，并保存本地
分析：

1. 拼接url
2. 发送请求
3. 保存到本地

## 使用urllib库实现

### 导入所需模块

```python
from urllib import request
from urllib import parse
```

### 拼接url

```python
url = 'http://www.baidu.com/s?wd={}'
wd = input('请输入要搜索的内容：')
params = parse.quote(wd)
full_url = url.format(params)
```

### 发送请求

- 创建请求对象-Request
- 获取响应对象-urlopen
- 读取响应对象-read

```python
# 重构请求头
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0) Gecko/20100101 Firefox/6.0'}
# 创建请求对象
req = request.Request(full_url, headers=headers)
# 获取响应对象
resp = request.urlopen(req)
# 读取响应对象
html = resp.read().decode('utf-8')
```

### 保存到本地

把爬取的网页保存至本地，此处需要使用 Python 编程的文件 IO 操作，代码如下：

```py
filename = word+'.html'
with open(filename, 'w', encoding='utf-8') as f:
    f.write(html)
```

## 函数式编程实现

函数式编程，就是把函数当作参数传递给另一个函数，然后由另一个函数来调用这个函数，从而实现代码的复用。

```python
  from urllib import request
  from urllib import parse

  def get_url(keyword):
    url = 'http://www.baidu.com/s?wd={}'
    params = parse.quote(keyword)
    full_url = url.format(params)
    return full_url

  def get_html(url):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0) Gecko/20100101 Firefox/6.0'}
    req = request.Request(url, headers=headers)
    resp = request.urlopen(req)
    html = resp.read().decode('utf-8')
    return html

  def save_html(html, keyword):
    filename = keyword + '.html'
    with open(filename, 'w', encoding='utf-8') as f:
      f.write(html)

  if __name__ == '__main__':
    word = input('请输入要搜索的内容：')
    url = get_url(word)
    html = get_html(url)
    save_html(html, word)
```